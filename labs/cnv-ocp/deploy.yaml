---
# Run it with:
#   ap labs/cnv-ocp/deploy.yaml

- name: 'Clean cnv-ocp lab'
  ansible.builtin.import_playbook: ../../playbooks/jobs/clean-lab.yml
  vars:
    lab_name: 'cnvn'
  tags:
    - 'clean'
    - 'never'

- name: 'Import ABI playbook'
  ansible.builtin.import_playbook: ../../playbooks/base/abi.yaml
  tags:
    - 'ocp'
  vars:
    lab_name: 'cnvn'
    lab_abi_ip: "{{ lab_node_network_base }}41"
    lab_api_ips: ["{{ lab_node_network_base }}108"]
    lab_ingress_ips: ["{{ lab_node_network_base }}109"]
    lab_node_cpus: 24
    lab_node_memory: 56000
    lab_node_disk_data: 300
    lab_hosts:
      - {id: '41', role: 'master'}
      - {id: '42', role: 'master'}
      - {id: '43', role: 'master'}
    start_install: true

- name: 'Setup Openshift Data Foundation (ODF)'
  ansible.builtin.import_playbook: ../../playbooks/setup/odf.yaml
  tags:
    - 'postinst'
    - 'odf'
  vars:
    lab_name: 'cnvn'
    ocp_odf_on_masters: True
    ocp_odf_storage_nodes:
      - 'cnvn-master-1'
      - 'cnvn-master-2'
      - 'cnvn-master-3'

- name: 'Import MCE setup playbook'
  ansible.builtin.import_playbook: ../../playbooks/setup/mce.yaml
  tags:
    - 'postinst'
    - 'mce'
  vars:
    lab_name: 'cnvn'
    ocp_assisted_service_ui: true

- name: 'Setup Container Native Virtualization (CNV)'
  gather_facts: false
  hosts: ['lab']

  vars:
    lab_name: 'cnvn'
  environment:
    KUBECONFIG: "/root/labs/{{ lab_name }}/deploy/auth/kubeconfig"

  roles:
    - role: 'ocp_cnv'
      vars:
        ocp_cnv_path: "/root/labs/{{ lab_name }}/config"
      tags:
        - 'postinst'
        - 'cnv'

- name: 'Setup fakefish'
  gather_facts: false
  hosts: ['lab']

  vars:
    lab_name: 'cnvn'
    fakefish_image: 'quay.io/mlorenzofr/fakefish:latest'
    config_path: "/root/labs/{{ lab_name }}/config/fakefish"
    lab_local_path: '/ansible/labs/cnv-ocp'
  environment:
    KUBECONFIG: "/root/labs/{{ lab_name }}/deploy/auth/kubeconfig"

  tags:
    - 'never'
    - 'fakefish'

  tasks:
    - name: 'Create fakefish manifest directory'
      ansible.builtin.file:
        path: "{{ config_path }}"
        state: 'directory'
        owner: 'root'
        group: 'root'
        mode: '0755'

    - name: 'Copy fakefish rbac manifest'
      ansible.builtin.copy:
        src: "{{ lab_local_path }}/manifest/fakefish/fakefish-rbac.yaml"
        dest: "{{ config_path }}/fakefish-rbac.yaml"
        owner: 'root'
        group: 'root'
        mode: '0644'

    - name: 'Apply fakefish rbac manifest'
      kubernetes.core.k8s:
        state: 'present'
        src: "{{ config_path }}/fakefish-rbac.yaml"
      ignore_errors: "{{ ansible_check_mode }}"

    # Create fakefish deployment manifests, one per each VM
    - name: 'Create fakefish deployment manifest'
      ansible.builtin.template:
        src: 'fakefish.yaml.j2'
        dest: "{{ config_path }}/fakefish-deploy-{{ bmc_name }}.yaml"
        mode: '0644'
      loop:
        - 'cnvn-spoke-1'
        - 'cnvn-spoke-2'
        - 'cnvn-spoke-3'
      loop_control:
        loop_var: bmc_name

    - name: 'Apply fakefish deployment manifests'
      kubernetes.core.k8s:
        state: 'present'
        src: "{{ config_path }}/fakefish-deploy-{{ bmc_name }}.yaml"
      loop:
        - 'cnvn-spoke-1'
        - 'cnvn-spoke-2'
        - 'cnvn-spoke-3'
      loop_control:
        loop_var: bmc_name
      ignore_errors: "{{ ansible_check_mode }}"

- name: 'Setup spoke cluster (using VMs)'
  gather_facts: false
  hosts: ['lab']

  vars:
    lab_name: 'cnvn'
  environment:
    KUBECONFIG: "/root/labs/{{ lab_name }}/deploy/auth/kubeconfig"

  tags:
    - 'never'
    - 'spoke'

  tasks:
    # Configure M3 to watch in all namespaces
    - name: 'Set watchAllNamespaces for provisioning'
      kubernetes.core.k8s:
        definition:
          apiVersion: 'metal3.io/v1alpha1'
          kind: 'Provisioning'
          metadata:
            name: 'provisioning-configuration'
          spec:
            watchAllNamespaces: true

    # This is the ClusterImageSet used in our ClusterInstance definition
    - name: 'Make spoke cluster image visible'
      kubernetes.core.k8s:
        definition:
          apiVersion: 'hive.openshift.io/v1'
          kind: 'ClusterImageSet'
          metadata:
            name: 'img4.18.16-x86-64-appsub'
            labels:
              visible: 'true'

    - name: 'Create spoke cluster namespace'
      kubernetes.core.k8s:
        name: spoke
        api_version: v1
        kind: Namespace
        state: present

    - name: 'Create pull-secret for spoke cluster'
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: 'v1'
          kind: 'Secret'
          type: 'kubernetes.io/dockerconfigjson'
          metadata:
            name: 'pullsecret-cluster-spoke'
            namespace: 'spoke'
          data:
            .dockerconfigjson: "{{ ocp_pullsecret_b64 }}"

    - name: 'Create secrets for BMC credentials'
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: 'v1'
          kind: 'Secret'
          type: 'Opaque'
          metadata:
            name: "cnvn-spoke-{{ item }}-bmc-secret"
            namespace: 'spoke'
          data:
            password: "{{ ocp_bmc_password }}"
            username: "{{ ocp_bmc_username }}"
      loop: [1, 2, 3]

    - name: 'Create pull-secret for infraenv'
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: 'v1'
          kind: 'Secret'
          type: 'kubernetes.io/dockerconfigjson'
          metadata:
            name: "pull-secret-spoke"
            namespace: 'spoke'
          data:
            .dockerconfigjson: "{{ ocp_pullsecret_b64 }}"

- name: 'Setup VMs'
  gather_facts: false
  hosts: ['lab']

  vars:
    lab_name: 'cnvn'
  environment:
    KUBECONFIG: "/root/labs/{{ lab_name }}/deploy/auth/kubeconfig"

  tags:
    - 'never'
    - 'vms'

  tasks:
    - name: 'Get current Cluster Network Operator configuration'
      kubernetes.core.k8s_info:
        kind: 'Network'
        api_version: 'operator.openshift.io/v1'
        name: 'cluster'
      register: cno_config

    - name: 'Ensure spec.additionalNetworks key exists'
      kubernetes.core.k8s_json_patch:
        kind: 'Network'
        api_version: 'operator.openshift.io/v1'
        name: 'cluster'
        patch:
          - op: add
            path: /spec/additionalNetworks
            value: []
      when: cno_config.resources[0].spec.additionalNetworks is not defined

    - name: 'Re-read CNO configuration after potential patch'
      kubernetes.core.k8s_info:
        kind: 'Network'
        api_version: 'operator.openshift.io/v1'
        name: 'cluster'
      register: cno_config_updated

    # Enable DHCP IPAM CNI Daemon
    - name: 'Enable DHCP IPAM CNI Daemon'
      kubernetes.core.k8s_json_patch:
        api_version: 'operator.openshift.io/v1'
        kind: 'Network'
        name: 'cluster'
        patch:
          - op: add
            path: /spec/additionalNetworks/-
            value:
              name: 'macvlan-dhcp-cno-trigger'
              type: 'Raw'
              rawCNIConfig: |
                  {
                    "cniVersion": "0.4.0",
                    "name": "macvlan-dhcp-cno-trigger",
                    "type": "macvlan",
                    "ipam": {
                      "type": "dhcp"
                    }
                  }
      when: >
        cno_config_updated.resources[0].spec.additionalNetworks
        | selectattr('name', 'equalto', 'macvlan-dhcp-cno-trigger')
        | list | length == 0

- name: 'Extract spoke cluster configuration'
  ansible.builtin.import_playbook: ../../playbooks/jobs/hive-config.yml
  vars:
    lab_name: 'cnvn'
    lab_path: '/root/labs'
    hive_cluster_name: 'spoke'
    hive_ns: 'spoke'
  tags:
    - 'spoke-config'
    - 'never'
